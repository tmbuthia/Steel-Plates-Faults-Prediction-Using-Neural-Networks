{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d561ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395936ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Steel-Faults.nna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbad803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file and read contents\n",
    "with open('Steel-Faults.nna', 'r') as f:\n",
    "    contents = f.readlines()\n",
    "\n",
    "# Process each line\n",
    "data = []\n",
    "for line in contents:\n",
    "    # Split each line by tabs and convert to a list of values\n",
    "    values = line.strip().split('\\t')\n",
    "    data.append(values)\n",
    "\n",
    "# Print processed data\n",
    "# for row in data:\n",
    "#    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c7f6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>...</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scratch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>270900.0</td>\n",
       "      <td>270944.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24220.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>-0.2913</td>\n",
       "      <td>0.5822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>645.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>2538079.0</td>\n",
       "      <td>2538108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11397.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7931</td>\n",
       "      <td>-0.1756</td>\n",
       "      <td>0.2984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>1553913.0</td>\n",
       "      <td>1553931.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7972.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>369370.0</td>\n",
       "      <td>369415.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18996.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>-0.1568</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1289.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>498078.0</td>\n",
       "      <td>498335.0</td>\n",
       "      <td>2409.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>246930.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9338</td>\n",
       "      <td>-0.1992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
       "0       42.0       50.0   270900.0   270944.0         267.0         17.0   \n",
       "1      645.0      651.0  2538079.0  2538108.0         108.0         10.0   \n",
       "2      829.0      835.0  1553913.0  1553931.0          71.0          8.0   \n",
       "3      853.0      860.0   369370.0   369415.0         176.0         13.0   \n",
       "4     1289.0     1306.0   498078.0   498335.0        2409.0         60.0   \n",
       "\n",
       "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  \\\n",
       "0         44.0            24220.0                   76.0   \n",
       "1         30.0            11397.0                   84.0   \n",
       "2         19.0             7972.0                   99.0   \n",
       "3         45.0            18996.0                   99.0   \n",
       "4        260.0           246930.0                   37.0   \n",
       "\n",
       "   Maximum_of_Luminosity  ...  Orientation_Index  Luminosity_Index  \\\n",
       "0                  108.0  ...             0.8182           -0.2913   \n",
       "1                  123.0  ...             0.7931           -0.1756   \n",
       "2                  125.0  ...             0.6667           -0.1228   \n",
       "3                  126.0  ...             0.8444           -0.1568   \n",
       "4                  126.0  ...             0.9338           -0.1992   \n",
       "\n",
       "   SigmoidOfAreas  Pastry  Z_Scratch  K_Scratch  Stains  Dirtiness  Bumps  \\\n",
       "0          0.5822     1.0        0.0        0.0     0.0        0.0    0.0   \n",
       "1          0.2984     1.0        0.0        0.0     0.0        0.0    0.0   \n",
       "2          0.2150     1.0        0.0        0.0     0.0        0.0    0.0   \n",
       "3          0.5212     1.0        0.0        0.0     0.0        0.0    0.0   \n",
       "4          1.0000     1.0        0.0        0.0     0.0        0.0    0.0   \n",
       "\n",
       "   Other_Faults  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, dtype=float,)\n",
    "df.columns = [\"X_Minimum\",\"X_Maximum\",\"Y_Minimum\",\"Y_Maximum\",\"Pixels_Areas\",\"X_Perimeter\",\"Y_Perimeter\",\"Sum_of_Luminosity\",\"Minimum_of_Luminosity\",\"Maximum_of_Luminosity\",\"Length_of_Conveyer\",\"TypeOfSteel_A300\",\"TypeOfSteel_A400\",\"Steel_Plate_Thickness\",\"Edges_Index\",\"Empty_Index\",\"Square_Index\",\"Outside_X_Index\",\"Edges_X_Index\",\"Edges_Y_Index\",\"Outside_Global_Index\",\"LogOfAreas\",\"Log_X_Index\",\"Log_Y_Index\",\"Orientation_Index\",\"Luminosity_Index\",\"SigmoidOfAreas\",\"Pastry\",\"Z_Scratch\",\"K_Scratch\",\"Stains\",\"Dirtiness\",\"Bumps\",\"Other_Faults\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29e7a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical variables\n",
    "X = df.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400'], axis=1)\n",
    "\n",
    "# the categorical variables are dropped as we are focusing on numeric attributes only.\n",
    "\n",
    "# Split features and labels\n",
    "y = df[['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']]\n",
    "X = X.drop(['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults'], axis=1)\n",
    "\n",
    "# One-hot encode the labels (y) since they are multi-class.\n",
    "# One-hot encode labels\n",
    "y = pd.get_dummies(y, columns=y.columns)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc97e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 18.6248 - val_accuracy: 0.5013 - val_loss: 18.9658\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.7162 - loss: 21.6508 - val_accuracy: 0.9100 - val_loss: 37.0176\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.8660 - loss: 45.7427 - val_accuracy: 0.7815 - val_loss: 87.5923\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.7379 - loss: 107.3940 - val_accuracy: 0.7147 - val_loss: 182.4337\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7076 - loss: 213.5909 - val_accuracy: 0.7224 - val_loss: 317.5440\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6982 - loss: 351.3470 - val_accuracy: 0.6838 - val_loss: 479.9661\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6820 - loss: 530.9420 - val_accuracy: 0.6581 - val_loss: 624.3719\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6674 - loss: 685.3930 - val_accuracy: 0.7095 - val_loss: 776.4418\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 856.5823 - val_accuracy: 0.5116 - val_loss: 914.2678\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6270 - loss: 978.6071 - val_accuracy: 0.6607 - val_loss: 1095.5393\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.6685 - loss: 1152.5321 - val_accuracy: 0.2674 - val_loss: 1272.2332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3076f3390>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(Dense(64, activation='relu')) # Hidden layer\n",
    "model.add(Dense(32, activation='relu')) # Hidden layer\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb6e79a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.50\n",
      "Test loss: 18.9658\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.54      0.67       360\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       389\n",
      "   macro avg       0.09      0.05      0.07       389\n",
      "weighted avg       0.82      0.50      0.62       389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test.values, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "print(classification_report(y_test_classes, y_pred_classes, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd1e54",
   "metadata": {},
   "source": [
    "### Summary of returns\n",
    "Test Accuracy: 0.50 which means it correctly classified 50% of the instances.\n",
    "\n",
    "Test Loss: 18.9658\n",
    "The loss value is low, indicating that the  model's predictions match the actual labels at a decent rate.\n",
    "\n",
    "Classification Report\n",
    "The classification report provides precision, recall, and F1-score for each class, along with support (the number of instances in the test set for each class).\n",
    "\n",
    "For class 0 (likely \"Pastry\" fault):\n",
    "Precision: 0.88 (88% of instances predicted as class 0 were actually class 0)\n",
    "Recall: 0.54 (54% of actual class 0 instances were correctly predicted)\n",
    "F1-score: 0.67 (harmonic mean of precision and recall)\n",
    "Support: 360 instances\n",
    "\n",
    "For class 1 (likely \"Z_Scratch\" fault):\n",
    "Precision, recall, and F1-score are all 0.00, indicating that the model failed to correctly predict any instances.\n",
    "Support: 29 instances\n",
    "\n",
    "For classes 2 and 4 (likely \"K_Scratch\" and \"Stains\" faults):\n",
    "Precision, recall, and F1-score are all 0.00, indicating that the model failed to correctly predict any instances of these classes.\n",
    "Support: 0 instances these classes may not have been present in the test set\n",
    "\n",
    "The model performs well for class 0 but fails to identify class 1 correctly and has no samples for class 2 and class 4 in the test set. \n",
    "\n",
    "For classes  6, 7, 8, 10, 12, 13:\n",
    "Precision, recall, and F1-score are all 0.00, indicating that the model failed to correctly predict any instances of these classes.\n",
    "Support: 0 instances these classes may not have been present in the test set\n",
    "There are no samples of these classes in the test set, so these metrics are not applicable\n",
    "\n",
    "Macro Average:\n",
    "\n",
    "Precision: 0.09, Recall: 0.05 ,F1-Score: 0.07\n",
    "These averages are low, reflecting poor performance for classes other than class 0.\n",
    "\n",
    "Weighted Average:\n",
    "\n",
    "Precision: 0.82, Recall: 0.50, F1-Score: 0.62\n",
    "These averages are weighted by support (the number of true instances for each class). They are higher due to the large number of class 0 samples dominating the metrics.\n",
    "\n",
    "In summary, the model performed well in predicting the \"Pastry\" fault (class 0) but struggled with the other fault types, particularly \"Z_Scratch\" (class 1). The lower test loss indicates better prediction quality compared to the previous model, but the accuracy is still moderate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95a9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0c2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
